{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "timely-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "descending-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_trek_scripts = pd.read_json('../scripts/all_scripts_raw.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pacific-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_trek_lines = pd.read_json('../scripts/all_series_lines.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "explicit-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "tos_scripts = star_trek_scripts['TOS'].dropna()\n",
    "tng_scripts = star_trek_scripts['TNG'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cheap-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_tos = \n",
    "tos_list = []\n",
    "for i in tos_scripts:\n",
    "    tos_list.append(i)\n",
    "    \n",
    "merged_tos = \"\".join(tos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "classified-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_tng = \n",
    "tng_list = []\n",
    "for i in tng_scripts:\n",
    "    tng_list.append(i)\n",
    "    \n",
    "merged_tng = \"\".join(tng_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "satellite-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    pattern = '(page|PAGE|Page)(\\s+\\|\\s+)([0-9]+)(.*)$'\n",
    "    output_cleaned = re.sub('\\s$', '', string, flags=re.MULTILINE)\n",
    "    p=re.compile(pattern,re.MULTILINE)\n",
    "    output_cleaned = p.sub(\" \",output_cleaned)\n",
    "    return output_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "several-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = clean_text(merged_tos)\n",
    "check2 = clean_text(merged_tng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-commodity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "solid-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tos_full_show_cleaned.txt\", 'w', encoding='utf-8') as f:\n",
    "    f.writelines(check)\n",
    "    \n",
    "with open(\"tng_full_show_cleaned.txt\", 'w', encoding='utf-8') as ff:\n",
    "    ff.writelines(check2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "binary-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tos_full_show_cleaned.txt\",'r', encoding='utf-8') as f:\n",
    "    file_input=f.readlines()\n",
    "    \n",
    "with open(\"tng_full_show_cleaned.txt\",'r', encoding='utf-8') as ff:\n",
    "    file_input_2=ff.readlines()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-korea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-bradley",
   "metadata": {},
   "source": [
    "---\n",
    "**train and val The Original Series txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "extreme-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc =[]\n",
    "val_doc =[]\n",
    "for cnt, line in enumerate(file_input):\n",
    "#         print(cnt)\n",
    "        if cnt <= len(file_input)*0.90:\n",
    "            train_doc.append(line)\n",
    "        else:\n",
    "            val_doc.append(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "compound-theology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50557"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "boxed-objective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50557\n"
     ]
    }
   ],
   "source": [
    "## Write to file\n",
    "f = open('train_tos.txt', \"w+\", encoding='utf-8')\n",
    "count = 0\n",
    "for line in train_doc:\n",
    "    count=count+1\n",
    "    f.write(str(line))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "surprising-thermal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5617\n"
     ]
    }
   ],
   "source": [
    "## Write to file\n",
    "f = open('val_tos.txt', \"w+\", encoding='utf-8')\n",
    "count = 0\n",
    "for line in val_doc:\n",
    "    count=count+1\n",
    "    f.write(str(line))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-spectacular",
   "metadata": {},
   "source": [
    "---\n",
    "**tng train and val**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sought-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc =[]\n",
    "val_doc =[]\n",
    "for cnt, line in enumerate(file_input_2):\n",
    "#         print(cnt)\n",
    "        if cnt <= len(file_input_2)*0.90:\n",
    "            train_doc.append(line)\n",
    "        else:\n",
    "            val_doc.append(line)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vocal-vinyl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107339\n"
     ]
    }
   ],
   "source": [
    "## Write to file\n",
    "f = open('train_tng.txt', \"w+\", encoding='utf-8')\n",
    "count = 0\n",
    "for line in train_doc:\n",
    "    count=count+1\n",
    "    f.write(str(line))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cleared-summit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11926\n"
     ]
    }
   ],
   "source": [
    "## Write to file\n",
    "f = open('val_tng.txt', \"w+\", encoding='utf-8')\n",
    "count = 0\n",
    "for line in val_doc:\n",
    "    count=count+1\n",
    "    f.write(str(line))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-affiliate",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-sphere",
   "metadata": {},
   "source": [
    "**Star Wars txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "turned-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_newhope = open('./starwars_scripts/SW_EpisodeIV.txt','r', encoding='utf-8')\n",
    "sw_empire = open('./starwars_scripts/SW_EpisodeV.txt', 'r', encoding='utf-8')\n",
    "sw_jedi = open('./starwars_scripts/SW_EpisodeVI.txt', 'r', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "constitutional-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hope = sw_newhope.read()\n",
    "empire = sw_empire.read()\n",
    "jedi = sw_jedi.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "foster-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_original = new_hope+empire+jedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "satisfied-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_original;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "actual-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_SW(string):\n",
    "    pattern = '(\\s+\\|\\s+)([0-9]+)(.*)$'\n",
    "    output_cleaned = re.sub('\\s$', '', string, flags=re.MULTILINE)\n",
    "    p=re.compile(pattern,re.MULTILINE)\n",
    "    output_cleaned = p.sub(\" \",output_cleaned)\n",
    "    output_nodigit = ''.join(c for c in output_cleaned if not c.isdigit()).replace('\"\"', \"\")\n",
    "    \n",
    "    return output_nodigit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "known-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_3 = clean_text_SW(sw_original)\n",
    "check_3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mature-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sw_full_cleaned.txt\", 'w', encoding='utf-8') as fff:\n",
    "    fff.writelines(check_3)\n",
    "    \n",
    "with open(\"sw_full_cleaned.txt\", 'r', encoding='utf-8') as fff:\n",
    "      file_input_3=fff.readlines()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "altered-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_sw =[]\n",
    "val_doc_sw =[]\n",
    "for cnt_sw, line_sw in enumerate(file_input_3):\n",
    "#         print(cnt)\n",
    "        if cnt_sw <= len(file_input_3)*0.90:\n",
    "            train_doc_sw.append(line_sw)\n",
    "        else:\n",
    "            val_doc_sw.append(line_sw)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "close-champion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2274\n"
     ]
    }
   ],
   "source": [
    "# Write to file\n",
    "f = open('train_SW.txt', \"w+\", encoding='utf-8')\n",
    "count = 0\n",
    "for line_sw in train_doc_sw:\n",
    "    count=count+1\n",
    "    f.write(str(line_sw))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "passing-secretariat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50557"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "necessary-telephone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n"
     ]
    }
   ],
   "source": [
    "## Write to file\n",
    "f = open('val_SW.txt', \"w+\", encoding='utf-8')\n",
    "count = 0\n",
    "for line_sw in val_doc_sw:\n",
    "    count=count+1\n",
    "    f.write(str(line_sw))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-feelings",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-happening",
   "metadata": {},
   "source": [
    "**I like the format of the training and testing better than the original format. so Lets use that instead going forward.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "urban-album",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2526\n"
     ]
    }
   ],
   "source": [
    "full_doc_sw =[]\n",
    "for cnt_sw, line_sw in enumerate(file_input_3):\n",
    "#         print(cnt)\n",
    "        if cnt_sw <= len(file_input_3):\n",
    "            full_doc_sw.append(line_sw)\n",
    "\n",
    "# write to file\n",
    "f = open('full_SW.txt', \"w+\", encoding='utf-8')\n",
    "count = 0\n",
    "for line_sw in full_doc_sw:\n",
    "    count=count+1\n",
    "    f.write(str(line_sw))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "second-captain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56174\n"
     ]
    }
   ],
   "source": [
    "full_doc_st =[]\n",
    "for cnt_st, line_st in enumerate(file_input):\n",
    "#         print(cnt)\n",
    "        if cnt_st <= len(file_input):\n",
    "            full_doc_st.append(line_st)\n",
    "\n",
    "# write to file\n",
    "f = open('full_ST.txt', \"w+\", encoding='utf-8')\n",
    "count = 0\n",
    "for line_st in full_doc_st:\n",
    "    count=count+1\n",
    "    f.write(str(line_st))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "nominated-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119265\n"
     ]
    }
   ],
   "source": [
    "full_doc_tng =[]\n",
    "for cnt_st, line_st in enumerate(file_input_2):\n",
    "#         print(cnt)\n",
    "        if cnt_st <= len(file_input_2):\n",
    "            full_doc_tng.append(line_st)\n",
    "\n",
    "# write to file\n",
    "f = open('full_TNG.txt', \"w+\", encoding='utf-8')\n",
    "count = 0\n",
    "for line_st in full_doc_tng:\n",
    "    count=count+1\n",
    "    f.write(str(line_st))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-token",
   "metadata": {},
   "source": [
    "Okay lets make a combined dataset with starwars and startrek data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fossil-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sw_full_cleaned.txt', 'r', encoding='utf-8') as starwars:\n",
    "    file_sw = starwars.readlines()\n",
    "\n",
    "with open('tng_full_show_cleaned.txt', 'r', encoding='utf-8') as nextgen:\n",
    "    file_tng = nextgen.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "qualified-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_tng;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "silver-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('combined_sw_tng.txt', 'w', encoding='utf-8') as unnatural:\n",
    "    unnatural.writelines(file_sw +file_tng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "advance-clark",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-820f43827c21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_doc\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mval_doc\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcnt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munnatural\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#         print(cnt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munnatural\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.90\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "train_doc =[]\n",
    "val_doc =[]\n",
    "for cnt, line in enumerate(unnatural):\n",
    "#         print(cnt)\n",
    "        if cnt <= len(unnatural)*0.90:\n",
    "            train_doc.append(line)\n",
    "        else:\n",
    "            val_doc.append(line)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "partial-words",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50557\n"
     ]
    }
   ],
   "source": [
    "## Write to file\n",
    "f = open('train_Combine.txt', \"w+\", encoding='utf-8')\n",
    "count = 0\n",
    "for line in train_doc:\n",
    "    count=count+1\n",
    "    f.write(str(line))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "religious-criterion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50557"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "forced-dietary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5617\n"
     ]
    }
   ],
   "source": [
    "## Write to file\n",
    "f = open('val_Combine.txt', \"w+\", encoding='utf-8')\n",
    "count = 0\n",
    "for line in val_doc:\n",
    "    count=count+1\n",
    "    f.write(str(line))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-jungle",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-grain",
   "metadata": {},
   "source": [
    "**Okay lets get a full of each series.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "generic-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds9_scripts = star_trek_scripts['DS9'].dropna()\n",
    "voy_scripts = star_trek_scripts['VOY'].dropna()\n",
    "tas_scripts = star_trek_scripts['TAS'].dropna()\n",
    "ent_scripts = star_trek_scripts['ENT'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "close-puzzle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DS9', 'TOS', 'TAS', 'TNG', 'VOY', 'ENT'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_trek_scripts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adverse-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged = \n",
    "ds9_list = []\n",
    "for i in ds9_scripts:\n",
    "    ds9_list.append(i)\n",
    "    \n",
    "merged_ds9 = \"\".join(ds9_list)\n",
    "\n",
    "voy_list = []\n",
    "for i in voy_scripts:\n",
    "    voy_list.append(i)    \n",
    "merged_voy = \"\".join(voy_list)\n",
    "\n",
    "tas_list = []\n",
    "for i in tas_scripts:\n",
    "    tas_list.append(i)\n",
    "merged_tas = \"\".join(tas_list)\n",
    "\n",
    "ent_list = []\n",
    "for i in ent_scripts:\n",
    "    ent_list.append(i)\n",
    "merged_ent = \"\".join(ent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "narrative-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    pattern = '(page|PAGE|Page)(\\s+\\|\\s+)([0-9]+)(.*)$'\n",
    "    output_cleaned = re.sub('\\s$', '', string, flags=re.MULTILINE)\n",
    "    p=re.compile(pattern,re.MULTILINE)\n",
    "    output_cleaned = p.sub(\" \",output_cleaned)\n",
    "    return output_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "congressional-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_ds9 = clean_text(merged_ds9)\n",
    "check_voy = clean_text(merged_voy)\n",
    "check_tas = clean_text(merged_tas)\n",
    "check_ent = clean_text(merged_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-ferry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "oriented-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ds9_full_show_cleaned.txt\", 'w', encoding='utf-8') as f:\n",
    "    f.writelines(check_ds9)\n",
    "    \n",
    "with open(\"voy_full_show_cleaned.txt\", 'w', encoding='utf-8') as ff:\n",
    "    ff.writelines(check_voy)\n",
    "    \n",
    "with open(\"ent_full_show_cleaned.txt\", 'w', encoding='utf-8') as f:\n",
    "    f.writelines(check_ent)\n",
    "    \n",
    "with open(\"tas_full_show_cleaned.txt\", 'w', encoding='utf-8') as ff:\n",
    "    ff.writelines(check_tas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "empirical-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ds9_full_show_cleaned.txt\",'r', encoding='utf-8') as f:\n",
    "    file_input_ds9=f.readlines()\n",
    "    \n",
    "with open(\"voy_full_show_cleaned.txt\",'r', encoding='utf-8') as ff:\n",
    "    file_input_voy=ff.readlines()  \n",
    "    \n",
    "with open(\"ent_full_show_cleaned.txt\",'r', encoding='utf-8') as f:\n",
    "    file_input_ent=f.readlines()\n",
    "    \n",
    "with open(\"tas_full_show_cleaned.txt\",'r', encoding='utf-8') as ff:\n",
    "    file_input_tas=ff.readlines()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "peaceful-alignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121093\n"
     ]
    }
   ],
   "source": [
    "full_doc_ds9 =[]\n",
    "for cnt, line in enumerate(file_input_ds9):\n",
    "#         print(cnt)\n",
    "        if cnt <= len(file_input_ds9):\n",
    "            full_doc_ds9.append(line)\n",
    "\n",
    "# write to file\n",
    "f = open('full_ds9.txt', \"w+\", encoding='utf-8')\n",
    "count = 0\n",
    "for line in full_doc_ds9:\n",
    "    count=count+1\n",
    "    f.write(str(line))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "secure-outreach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128406\n"
     ]
    }
   ],
   "source": [
    "full_doc_voy =[]\n",
    "for cnt, line in enumerate(file_input_voy):\n",
    "#         print(cnt)\n",
    "        if cnt <= len(file_input_voy):\n",
    "            full_doc_voy.append(line)\n",
    "\n",
    "# write to file\n",
    "f = open('full_voy.txt', \"w+\", encoding='utf-8')\n",
    "count = 0\n",
    "for line in full_doc_voy:\n",
    "    count=count+1\n",
    "    f.write(str(line))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "muslim-bikini",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8859\n"
     ]
    }
   ],
   "source": [
    "full_doc_tas =[]\n",
    "for cnt, line in enumerate(file_input_tas):\n",
    "#         print(cnt)\n",
    "        if cnt <= len(file_input_tas):\n",
    "            full_doc_tas.append(line)\n",
    "\n",
    "# write to file\n",
    "f = open('full_tas.txt', \"w+\", encoding='utf-8')\n",
    "count = 0\n",
    "for line in full_doc_tas:\n",
    "    count=count+1\n",
    "    f.write(str(line))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "objective-adrian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63074\n"
     ]
    }
   ],
   "source": [
    "full_doc_ent =[]\n",
    "for cnt, line in enumerate(file_input_ent):\n",
    "#         print(cnt)\n",
    "        if cnt <= len(file_input_ent):\n",
    "            full_doc_ent.append(line)\n",
    "\n",
    "# write to file\n",
    "f = open('full_ent.txt', \"w+\", encoding='utf-8')\n",
    "count = 0\n",
    "for line in full_doc_ent:\n",
    "    count=count+1\n",
    "    f.write(str(line))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-glucose",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
